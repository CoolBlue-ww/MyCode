{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T08:56:42.567783Z",
     "start_time": "2025-05-28T08:56:40.325421Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "张量的创建以及初始化。\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "demo = [[1, 2], [2, 3], [2, 5], [0, 29]]\n",
    "\n",
    "array = np.array(demo)\n",
    "\n",
    "print(f\"通过numpy，将 {type(demo)} --> {type(array)}\")\n",
    "\n",
    "tensor_ = torch.tensor(demo)\n",
    "_tensor = torch.from_numpy(array)\n",
    "\n",
    "print(f\"通过torch.tensor来实现 {type(demo)} --> {type(tensor_)}\")\n",
    "print(f\"通过torch.from_numpy来实现 {type(array)} --> {type(_tensor)}\")\n",
    "\n",
    "\n",
    "# 随机张量\n",
    "shape = (5, 5,)  # 张量的形状\n",
    "\n",
    "tensor1 = torch.ones(shape)\n",
    "print(f\"这是随机生成的由一为元素构成的张量：\\n {tensor1}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "tensor2 = torch.zeros(shape)\n",
    "print(f\"这是随机生成的由零为元素构成的张量: \\n {tensor2}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "tensor3 = torch.rand(shape)\n",
    "print(f\"这是由零到一之间的随机数为元素生成的张量： \\n {tensor3}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-\" * 70)\n",
    "print(\"在原有的张量基础上，创建一个具有相同形状和设备信息的张量：\")\n",
    "\n",
    "\n",
    "# 对原有的张量使用1,0,或者随机张量进行覆盖修改。\n",
    "list_ = [[1, 2, 3], [2, 6, 7], [3, 4, 6], [5, 6, 10]]\n",
    "array_ = np.array(list_)\n",
    "tensor_ = torch.from_numpy(array_)\n",
    "print(f\"--> List: \\n{list_}\")\n",
    "print(f\"--> Array: \\n{array_}\")\n",
    "print(f\"--> Tensor: \\n{tensor_}\")\n",
    "print(\"<\" + \"-\" * 70 + \">\")\n",
    "tensor_1 = torch.zeros_like(tensor_)\n",
    "print(f\"将原张量的元素全部变为0： \\n{tensor_1}\")\n",
    "print(\"-\" * 70)\n",
    "tensor_2 = torch.ones_like(tensor_)\n",
    "print(f\"将原张量的元素全部变为1： \\n{tensor_2}\")\n",
    "print(\"-\" * 70)\n",
    "tensor_3 = torch.rand_like(tensor_, dtype=torch.float)\n",
    "print(f\"将原张量的元素变为0-1之间的随机数： \\n{tensor_3}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过numpy，将 <class 'list'> --> <class 'numpy.ndarray'>\n",
      "通过torch.tensor来实现 <class 'list'> --> <class 'torch.Tensor'>\n",
      "通过torch.from_numpy来实现 <class 'numpy.ndarray'> --> <class 'torch.Tensor'>\n",
      "这是随机生成的由一为元素构成的张量：\n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "--------------------------------------------------\n",
      "这是随机生成的由零为元素构成的张量: \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "--------------------------------------------------\n",
      "这是由零到一之间的随机数为元素生成的张量： \n",
      " tensor([[0.5374, 0.3768, 0.6241, 0.4075, 0.4195],\n",
      "        [0.2235, 0.0712, 0.6312, 0.7126, 0.7894],\n",
      "        [0.3703, 0.7517, 0.5220, 0.0088, 0.7283],\n",
      "        [0.6338, 0.0036, 0.3246, 0.5362, 0.0519],\n",
      "        [0.3004, 0.0851, 0.2528, 0.1090, 0.1261]])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "在原有的张量基础上，创建一个具有相同形状和设备信息的张量：\n",
      "--> List: \n",
      "[[1, 2, 3], [2, 6, 7], [3, 4, 6], [5, 6, 10]]\n",
      "--> Array: \n",
      "[[ 1  2  3]\n",
      " [ 2  6  7]\n",
      " [ 3  4  6]\n",
      " [ 5  6 10]]\n",
      "--> Tensor: \n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 2,  6,  7],\n",
      "        [ 3,  4,  6],\n",
      "        [ 5,  6, 10]])\n",
      "<---------------------------------------------------------------------->\n",
      "将原张量的元素全部变为0： \n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "----------------------------------------------------------------------\n",
      "将原张量的元素全部变为1： \n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "----------------------------------------------------------------------\n",
      "将原张量的元素变为0-1之间的随机数： \n",
      "tensor([[0.8086, 0.5098, 0.6579],\n",
      "        [0.9419, 0.6105, 0.5865],\n",
      "        [0.5110, 0.2509, 0.9020],\n",
      "        [0.0568, 0.9662, 0.6008]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上面的这个代码用于张量的初始化和覆盖已有张量：\n",
    "A.转换张量：\n",
    "    1.对于非列表的数据结构：\n",
    "      a.先将其转换成列表，然后再根据后续的步骤操作进行处理。\n",
    "    2.对于列表的数据结构：\n",
    "        a.直接将其转换成张量：\n",
    "          tensor = torch.tensor(list)\n",
    "        b.先将其转换成numpy数组，再将其转换成张量：\n",
    "          array = np.array(list)\n",
    "          tensor = torch.from_numpy(array)\n",
    "    3.对于numpy数组的数据结构：\n",
    "        a.直接将其转换成tensor：\n",
    "          tensor = torch.from_numpy(array)\n",
    "\n",
    "B.随机张量：\n",
    "    <->.首先定义张量的形状：\n",
    "        shape = (x, y,)\n",
    "    1.随机元素为0的张量：\n",
    "      tensor = torch.zeros(shape)\n",
    "    2.随机元素为[0, 1)之间的浮点数：\n",
    "      tensor = torch.rand(shape)\n",
    "    3.随机元素为1的张量：\n",
    "      tensor = torch.ones(shape)\n",
    "\n",
    "C.修改覆盖张量：\n",
    "    <->.修改后的张量形状和设备信息不会发送改变。\n",
    "    1.将原张量元素全部修改为0：\n",
    "      new_tensor = torch.zeros_like(base_tensor)\n",
    "    2.将原张量元素全部修改为[0,1)之间的浮点数：\n",
    "      new_tensor = torch.rand_like(base_tensor, dtype=torch.gloat)  # 必须显式指定数据类型为浮点数。\n",
    "    3.将原张量元素全部修改为1：\n",
    "      new_tensor = torch.ones_like(base_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e7ad033d5168f02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:57:23.135319Z",
     "start_time": "2025-05-28T08:57:23.120540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "张量的属性\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "\n",
    "# 形状，数据类型，设备信息。\n",
    "tensor = torch.rand(3, 4)\n",
    "tensor_shape = tensor.shape\n",
    "tensor_dtype = tensor.dtype\n",
    "tensor_device = tensor.device\n",
    "print(f\"这个随机生成的3X4张量，它的形状是 {tensor_shape} 数据类型是 {tensor_dtype} 设备信息是 {tensor_device}\")\n"
   ],
   "id": "f8ba89c4fd3392af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个随机生成的3X4张量，它的形状是 torch.Size([3, 4]) 数据类型是 torch.float32 设备信息是 cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这里通过张量的三个属性来获取张量的信息，这三个属性分别为shape，dtype，device。",
   "id": "c50c2dad2cc3c93a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T08:57:13.879191Z",
     "start_time": "2025-05-28T08:57:13.865734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "张量转移\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "\n",
    "shape = (3, 3)\n",
    "tensor = torch.rand(shape, dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "    print(f\"当前张量位于： {tensor.device}\")\n",
    "else:\n",
    "    print(\"加速不可用！\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "21d7e888652196ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加速不可用！\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "此处判断硬件上是否存在加速设备，如果存在就将张量转移到加速设备上。",
   "id": "f13dff56b3cabcd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T10:22:53.155402Z",
     "start_time": "2025-05-28T10:22:53.083834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "张量的索引和切片\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# 定义一个列表\n",
    "lt = [\n",
    "    [1, 1, 2, 3, 4, 5, 6],\n",
    "    [2, 1, 2, 3, 4, 5, 6],\n",
    "    [3, 1, 2, 3, 4, 5, 6],\n",
    "    [4, 1, 2, 3, 4, 5, 6],\n",
    "    [5, 1, 2, 3, 4, 5, 6],\n",
    "    [6, 1, 2, 3, 4, 5, 6]\n",
    "]\n",
    "# 将列表转换成张量,这个张量是6 * 7的形状。按照数字的增长顺序来定义，方便观察张量的切片和索引操作。\n",
    "tr = torch.tensor(lt)\n",
    "# 打印这个张量\n",
    "print(tr)\n",
    "\n",
    "# 打印第一行和最一行\n",
    "print(tr[0])\n",
    "print(tr[-1])\n",
    "\n",
    "# 打印从第二行到倒数第二行\n",
    "print(tr[1:-1])\n",
    "\n",
    "# 修改第一行的张量\n",
    "tr[0, :] = torch.tensor([5, 2, 0, 1, 3, 4, 8])\n",
    "print(tr)\n",
    "\n",
    "# 打印张量的第一列\n",
    "print(tr[:, 0])\n",
    "\n",
    "# 打印张量的最后一列\n",
    "print(tr[:, -1])\n",
    "print(tr[..., -1])\n",
    "\n",
    "# 打印中间多列\n",
    "print(tr[..., 0:-1])\n",
    "\n",
    "# 修改第一列的张量\n",
    "tr[:, 0] = 10\n",
    "print(tr)\n",
    "\n",
    "# 打印第一行，第一列到第二列的张量。\n",
    "print(tr[0:1, 0:3])\n",
    "\n",
    "\n",
    "print(\"------------------分割线---------------------\")\n",
    "\n",
    "\n",
    "# 创建一个三维张量，从列表开始自定义。\n",
    "li = [\n",
    "    [\n",
    "        [1, 2],\n",
    "        [1, 2],\n",
    "        [1, 2]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2],\n",
    "        [1, 2],\n",
    "        [1, 2]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2],\n",
    "        [1, 2],\n",
    "        [1, 2]\n",
    "    ]\n",
    "]\n",
    "\n",
    "te = torch.tensor(li)\n",
    "# 打印这个三维张量\n",
    "print(te)\n",
    "# 降维取出\n",
    "print(te[..., 0])\n",
    "\n",
    "print(te[0:2, 0:2, 0])\n",
    "\n",
    "\n",
    "print(\"-----------------------分割线---------------------------\")\n",
    "# 对于后面为...的情况出现在高维张量中.\n",
    "\n",
    "list__ = [\n",
    "    [\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6],\n",
    "        [1, 2, 3, 4, 5, 6]\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "tensor__ = torch.tensor(list__)\n",
    "\n",
    "print(tensor__)\n",
    "\n",
    "print(tensor__[0:2, ...])\n",
    "\n",
    "print(tensor__[0])\n",
    "\n",
    "a = torch.ones(1, 4)\n",
    "print(a)\n",
    "print(a[0: 3])\n",
    "b = torch.tensor([1, 2, 3, 4])\n",
    "print(b[0:2])\n",
    "print([1, 2, 3, 4][0:2])"
   ],
   "id": "db0fb6ecd2e3323e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2, 3, 4, 5, 6],\n",
      "        [2, 1, 2, 3, 4, 5, 6],\n",
      "        [3, 1, 2, 3, 4, 5, 6],\n",
      "        [4, 1, 2, 3, 4, 5, 6],\n",
      "        [5, 1, 2, 3, 4, 5, 6],\n",
      "        [6, 1, 2, 3, 4, 5, 6]])\n",
      "tensor([1, 1, 2, 3, 4, 5, 6])\n",
      "tensor([6, 1, 2, 3, 4, 5, 6])\n",
      "tensor([[2, 1, 2, 3, 4, 5, 6],\n",
      "        [3, 1, 2, 3, 4, 5, 6],\n",
      "        [4, 1, 2, 3, 4, 5, 6],\n",
      "        [5, 1, 2, 3, 4, 5, 6]])\n",
      "tensor([[5, 2, 0, 1, 3, 4, 8],\n",
      "        [2, 1, 2, 3, 4, 5, 6],\n",
      "        [3, 1, 2, 3, 4, 5, 6],\n",
      "        [4, 1, 2, 3, 4, 5, 6],\n",
      "        [5, 1, 2, 3, 4, 5, 6],\n",
      "        [6, 1, 2, 3, 4, 5, 6]])\n",
      "tensor([5, 2, 3, 4, 5, 6])\n",
      "tensor([8, 6, 6, 6, 6, 6])\n",
      "tensor([8, 6, 6, 6, 6, 6])\n",
      "tensor([[5, 2, 0, 1, 3, 4],\n",
      "        [2, 1, 2, 3, 4, 5],\n",
      "        [3, 1, 2, 3, 4, 5],\n",
      "        [4, 1, 2, 3, 4, 5],\n",
      "        [5, 1, 2, 3, 4, 5],\n",
      "        [6, 1, 2, 3, 4, 5]])\n",
      "tensor([[10,  2,  0,  1,  3,  4,  8],\n",
      "        [10,  1,  2,  3,  4,  5,  6],\n",
      "        [10,  1,  2,  3,  4,  5,  6],\n",
      "        [10,  1,  2,  3,  4,  5,  6],\n",
      "        [10,  1,  2,  3,  4,  5,  6],\n",
      "        [10,  1,  2,  3,  4,  5,  6]])\n",
      "tensor([[10,  2,  0]])\n",
      "------------------分割线---------------------\n",
      "tensor([[[1, 2],\n",
      "         [1, 2],\n",
      "         [1, 2]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 2],\n",
      "         [1, 2]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 2],\n",
      "         [1, 2]]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "-----------------------分割线---------------------------\n",
      "tensor([[[1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6]]])\n",
      "tensor([[[1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6],\n",
      "         [1, 2, 3, 4, 5, 6]]])\n",
      "tensor([[1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6],\n",
      "        [1, 2, 3, 4, 5, 6]])\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([1, 2])\n",
      "[1, 2]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "张量可以进行类似于numpy数组的索引和切片操作，还可以对其内容进行更新和修改。基本的格式就是类似于列表的索引操作那样，只不过张量可以横竖多个方向，在不同的层面之间用逗号隔开。每个逗号间隔间都可以使用a：b这种操作来对每个不同的层面进行选择。如果只有一个层面，那默认总行开始。张量还可以进行更新和修改，只是修改的内容要和选中的内容形状相同，数据格式相同。：表示全选，而...表示多个连续的:。对于切片出来的张量会比原来的张量低一个维度，如果一个维度只有一个数那可省略不写。对于一维的张量和列表十分类似。\n",
   "id": "7b92856fcade3a56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:01:23.086813Z",
     "start_time": "2025-05-31T09:01:23.070062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "连接张量\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "list1 = [1, 1, 1,1]\n",
    "list2 = [2, 2, 2, 2]\n",
    "list3 = [3, 3, 3, 3]\n",
    "\n",
    "ten1 = torch.tensor(list1)\n",
    "ten2 = torch.tensor(list2)\n",
    "ten3 = torch.tensor(list3)\n",
    "\n",
    "print(f\"Tensor1 is :\\n{ten1}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Tensor2 is: \\n{ten2}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Tensor3 is: \\n{ten3}\")\n",
    "print(\"-\" * 70)\n",
    "L = torch.cat([ten1, ten2, ten3], dim=0)\n",
    "print(L)\n",
    "print(\"-\" * 70)\n",
    "\n",
    "list_ = [\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3]\n",
    "]\n",
    "\n",
    "_list = [\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6]\n",
    "]\n",
    "\n",
    "_list_ = [\n",
    "    [7, 8, 9],\n",
    "    [7, 8, 9],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "tensor_ = torch.tensor(list_)\n",
    "_tensor = torch.tensor(_list)\n",
    "_tensor_ = torch.tensor(_list_)\n",
    "\n",
    "l = torch.cat([tensor_, _tensor, _tensor_], dim=1)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(tensor_)\n",
    "print(\"-\" * 70)\n",
    "print(_tensor)\n",
    "print(\"-\" * 70)\n",
    "print(_tensor_)\n",
    "print(\"-\" * 70)\n",
    "print(l)\n"
   ],
   "id": "1e18c484ccf0f3e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor1 is :\n",
      "tensor([1, 1, 1, 1])\n",
      "----------------------------------------------------------------------\n",
      "Tensor2 is: \n",
      "tensor([2, 2, 2, 2])\n",
      "----------------------------------------------------------------------\n",
      "Tensor3 is: \n",
      "tensor([3, 3, 3, 3])\n",
      "----------------------------------------------------------------------\n",
      "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "----------------------------------------------------------------------\n",
      "tensor([[4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6]])\n",
      "----------------------------------------------------------------------\n",
      "tensor([[7, 8, 9],\n",
      "        [7, 8, 9],\n",
      "        [7, 8, 9]])\n",
      "----------------------------------------------------------------------\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "相同形状的张量之间可以联结，也就是在相同的维度上，把其他张量的数据从后面加到原来的张量上。类似于在同一维度上的两个列表相加，但是值得注意的是链结完，张量的维度是依然不会变的。方法： Cat = torch.cat([tensor1, tensor2, tensor3], dim=维度)",
   "id": "1693ae0a3d505802"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d51077ab1a12104"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
